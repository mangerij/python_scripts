{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the important libraries. Note to plot, we need to unload the miniconda module from the MOOSE environment(this is done in bash right now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 30 days\n",
      "numbapro:1: ImportWarning: The numbapro package is deprecated in favour of the accelerate package. Please update your code to use equivalent functions from accelerate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------libraries detection-------------------------------\n",
      "Finding cublas\n",
      "\tlocated at /home/john/anaconda2/lib/libcublas.so.7.0.28\n",
      "\ttrying to open library...\tok\n",
      "Finding cusparse\n",
      "\tlocated at /home/john/anaconda2/lib/libcusparse.so.7.0.28\n",
      "\ttrying to open library...\tok\n",
      "Finding cufft\n",
      "\tlocated at /home/john/anaconda2/lib/libcufft.so.7.0.35\n",
      "\ttrying to open library...\tok\n",
      "Finding curand\n",
      "\tlocated at /home/john/anaconda2/lib/libcurand.so.7.0.28\n",
      "\ttrying to open library...\tok\n",
      "Finding nvvm\n",
      "\tlocated at /home/john/anaconda2/lib/libnvvm.so.3.0.0\n",
      "\ttrying to open library...\tok\n",
      "\tfinding libdevice for compute_20...\tok\n",
      "\tfinding libdevice for compute_30...\tok\n",
      "\tfinding libdevice for compute_35...\tok\n",
      "-------------------------------hardware detection-------------------------------\n",
      "Found 1 CUDA devices\n",
      "id 0        GeForce GTX 870M                              [SUPPORTED]\n",
      "                      compute capability: 3.0\n",
      "                           pci device id: 0\n",
      "                              pci bus id: 1\n",
      "Summary:\n",
      "\t1/1 devices are supported\n",
      "PASSED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from matplotlib import pyplot\n",
    "import math\n",
    "import numbapro # We use check_cuda() and vectorize\n",
    "from numbapro import vectorize, autojit, jit, cuda #vectorize for functions and cuda for cuda-u functions\n",
    "numbapro.check_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: GeForce GTX 870M\n",
      "Compute capability:  3.0 (Numba requires >= 2.0)\n",
      "Number of streaming multiprocessor: 7\n",
      "Number of cores per mutliprocessor: 192\n",
      "Number of cores on GPU: 1344\n"
     ]
    }
   ],
   "source": [
    "import numba.cuda  \n",
    "#this line from nbviewer.ipython.org/github/ContinuumIO/numbapro-examples/blob/master/webinars/2014_06_17/intro_to_gpu_python.ipynb\n",
    "my_gpu = numba.cuda.get_current_device()\n",
    "print \"Running on GPU:\", my_gpu.name\n",
    "cores_per_capability = {\n",
    "    1: 8,\n",
    "    2: 32,\n",
    "    3: 192,\n",
    "}\n",
    "cc = my_gpu.compute_capability\n",
    "print \"Compute capability: \", \"%d.%d\" % cc, \"(Numba requires >= 2.0)\"\n",
    "majorcc = cc[0]\n",
    "print \"Number of streaming multiprocessor:\", my_gpu.MULTIPROCESSOR_COUNT\n",
    "cores_per_multiprocessor = cores_per_capability[majorcc]\n",
    "print \"Number of cores per mutliprocessor:\", cores_per_multiprocessor\n",
    "total_cores = cores_per_multiprocessor * my_gpu.MULTIPROCESSOR_COUNT\n",
    "print \"Number of cores on GPU:\", total_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_loadtxt(filename, delimiter=',', skiprows=1, dtype=float):\n",
    "    def iter_func():\n",
    "        with open(filename, 'r') as infile:\n",
    "            for _ in range(skiprows):\n",
    "                next(infile)\n",
    "            for line in infile:\n",
    "                line = line.rstrip().split(delimiter)\n",
    "                for item in line:\n",
    "                    yield dtype(item)\n",
    "        iter_loadtxt.rowlength = len(line)\n",
    "\n",
    "    data = np.fromiter(iter_func(), dtype=dtype)\n",
    "    data = data.reshape((-1, iter_loadtxt.rowlength))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation function took 6.856306 seconds\n",
      "Correlation function took 8.636047 seconds\n",
      "Correlation function took 11.475216 seconds\n",
      "Correlation function took 15.230894 seconds\n",
      "Correlation function took 18.516755 seconds\n",
      "Correlation function took 25.754067 seconds\n",
      "Correlation function took 31.591189 seconds\n",
      "Correlation function took 32.404009 seconds\n",
      "Correlation function took 39.486959 seconds\n",
      "Correlation function took 49.906812 seconds\n",
      "Correlation function took 56.423196 seconds\n",
      "Correlation function took 69.420290 seconds\n",
      "Correlation function took 91.396321 seconds\n",
      "Correlation function took 104.393568 seconds\n",
      "Correlation function took 130.417927 seconds\n",
      "Correlation function took 176.614432 seconds\n",
      "Correlation function took 207.624661 seconds\n",
      "Correlation function took 218.468251 seconds\n",
      "Correlation function took 225.850659 seconds\n",
      "Correlation function took 242.397990 seconds\n",
      "Correlation function took 293.339138 seconds\n",
      "Correlation function took 324.132494 seconds\n",
      "Correlation function took 402.764100 seconds\n",
      "Correlation function took 417.715850 seconds\n",
      "Correlation function took 461.785450 seconds\n"
     ]
    }
   ],
   "source": [
    "#This code will import nodal polar vector values using the above iterative loader, define the GPU vectorized functions, \n",
    "# and then perform the correlation.\n",
    "\n",
    "@vectorize([\"float64(float64, float64, float64)\"], target='gpu') \n",
    "def Rfunct(r0, r1, r2):\n",
    "    return (r0 * r0 +  r1 * r1 + r2 * r2)**(0.5)\n",
    "\n",
    "@vectorize([\"float64(float64, float64, float64, float64, float64, float64)\"], target='gpu') \n",
    "def Corrfunct(polar0f, polar1f, polar2f, arg0, arg1, arg2):\n",
    "    return 1/(0.8 * 0.8) * (polar0f * arg0 + polar1f * arg1 + polar2f * arg2);\n",
    "\n",
    "for t in range(1,1):\n",
    "    file_load = iter_loadtxt('/media/john/My Passport/Sphere project data/run2--curl/data'+repr(t)+'.csv',delimiter=',',skiprows=1,dtype=float)\n",
    "    \n",
    "    polar0 = np.asarray([row[1] for row in file_load])\n",
    "    polar1 = np.asarray([row[2] for row in file_load])\n",
    "    polar2 = np.asarray([row[3] for row in file_load])\n",
    "     \n",
    "    polar0ave = np.mean(polar0)\n",
    "    polar1ave = np.mean(polar1)\n",
    "    polar2ave = np.mean(polar2)\n",
    "    \n",
    "    Polar0fluct = np.asarray(polar0 - polar0ave)\n",
    "    Polar1fluct = np.asarray(polar1 - polar1ave)\n",
    "    Polar2fluct = np.asarray(polar2 - polar2ave)\n",
    "    \n",
    "    r0 = np.asarray([row[4] for row in file_load])\n",
    "    r1 = np.asarray([row[5] for row in file_load])\n",
    "    r2 = np.asarray([row[6] for row in file_load])\n",
    "    \n",
    "    Cr = np.zeros(len(polar0));\n",
    "    R = np.zeros(len(polar0));\n",
    "\n",
    "    start = timer()\n",
    "    R = Rfunct(r0, r1, r2)\n",
    "    for k in xrange(len(polar0)-1):\n",
    "        Cr += Corrfunct(Polar0fluct, Polar1fluct, Polar2fluct, Polar0fluct[k], Polar1fluct[k], Polar2fluct[k])\n",
    "    vectoradd_time = timer() - start\n",
    "    \n",
    "    np.savetxt(\"/media/john/My Passport/Sphere project data/run2--curl/Cr_\"+repr(t)+\".csv\", Cr, delimiter=\",\")\n",
    "    np.savetxt(\"/media/john/My Passport/Sphere project data/run2--curl/r_\"+repr(t)+\".csv\", R, delimiter=\",\")\n",
    "    \n",
    "    print(\"Correlation function took %f seconds\" % vectoradd_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20504 , -0.22127 , -0.21911 , ..., -0.055346, -0.096231, -0.11383 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polar0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_load = iter_loadtxt('/media/john/My Passport/Sphere project data/run2--curl/data4.csv',delimiter=',',skiprows=1,dtype=float)\n",
    "    \n",
    "polar0 = np.asarray([row[1] for row in file_load])\n",
    "polar1 = np.asarray([row[2] for row in file_load])\n",
    "polar2 = np.asarray([row[3] for row in file_load])\n",
    "     \n",
    "polar0ave = np.mean(polar0)\n",
    "polar1ave = np.mean(polar1)\n",
    "polar2ave = np.mean(polar2)\n",
    "    \n",
    "Polar0fluct = np.asarray(polar0 - polar0ave)\n",
    "Polar1fluct = np.asarray(polar1 - polar1ave)\n",
    "Polar2fluct = np.asarray(polar2 - polar2ave)\n",
    "    \n",
    "r0 = np.asarray([row[4] for row in file_load])\n",
    "r1 = np.asarray([row[5] for row in file_load])\n",
    "r2 = np.asarray([row[6] for row in file_load])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7439, -0.55  , -1.2109, ..., -5.7475,  4.2625, -1.9002])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize([\"float64(float64, float64, float64)\"], target='gpu') \n",
    "def Rfunct(r0, r1, r2):\n",
    "    return (r0 * r0 +  r1 * r1 + r2 * r2)**(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1c7f1dc242eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolar0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolar0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mr0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#distance function\n",
    "dist = np.zeros((len(polar0),len(polar0)));\n",
    "                \n",
    "for j in range(0,len(polar0)):\n",
    "    for k in range(0,len(polar0)):\n",
    "        dist[j,k] = ((r0[j] - r0[k])**2 + (r1[j] - r1[k])**2 + (r2[j] - r2[k])**2)**0.5;\n",
    "\n",
    "\n",
    "\n",
    "#probably could \"gpuize\" the outer or inner loop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"/media/john/My Passport/Sphere project data/run2--curl/distfunct.csv\", dist, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661524334125543"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize([\"float64(float64, float64, float64, float64, float64, float64)\"], target='gpu') \n",
    "def distfunct(r0, r1, r2, arg0, arg1, arg2):\n",
    "    return ((r0 - arg0)**2 + (r1 - arg1)**2 + (r2 - arg2)**2)**0.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81082662,  0.        ,  0.7399886 , ...,  5.58453024,\n",
       "        5.6401178 ,  3.88298307])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.22126999999999999"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polar0[1] #sorted(dist[1]) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first bin up to get radial distribution function, \n",
    "#then use the bins to count the number of polar vectors and save their indices\n",
    "#then dot them, sum them plot vs r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81082662,  0.        ,  0.7399886 , ...,  5.58453024,\n",
       "        5.6401178 ,  3.88298307])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[Nbin, rtest1] = np.histogram(dist[1], bins=50, range=None, normed=False, weights=None, density=None)\n",
    "\n",
    "# data[1,3][0] is the distance between node 1 and node 3, \n",
    "# data[1,3][1] is the value of the dot product of the vector at node 1 and node 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81082662,  0.15475446])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's start at one point(index i = 1), histogram the distances as we scan along (index j != 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[Nbin, rtest1] = np.histogram(dist_vec, bins = 35, range=None, normed=False, weights=None, density=None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(rtest1[0:len(Nbin)],Nbin,'r.');\n",
    "plt.ylabel('N', fontsize = 27); plt.xlabel('r [nm]', fontsize = 27);\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   0,   8,   8,  21,  21,  41,  45,  71,  68, 102, 109, 135,\n",
       "       164, 173, 202, 246, 260, 302, 313, 364, 414, 449, 478, 514, 570,\n",
       "       605, 663, 748, 716, 815, 715, 604, 352, 332])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rtest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.21638577,  0.43277153,  0.6491573 ,  0.86554306,\n",
       "        1.08192883,  1.2983146 ,  1.51470036,  1.73108613,  1.94747189,\n",
       "        2.16385766,  2.38024343,  2.59662919,  2.81301496,  3.02940072,\n",
       "        3.24578649,  3.46217226,  3.67855802,  3.89494379,  4.11132955,\n",
       "        4.32771532,  4.54410109,  4.76048685,  4.97687262,  5.19325838,\n",
       "        5.40964415,  5.62602992,  5.84241568,  6.05880145,  6.27518721,\n",
       "        6.49157298,  6.70795875,  6.92434451,  7.14073028,  7.35711604,\n",
       "        7.57350181])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@vectorize([\"float64(float64, float64, float64, float64, float64, float64)\"], target='gpu') \n",
    "def distfunct(r0, r1, r2, arg0, arg1, arg2):\n",
    "    return ((r0 - arg0)**2 + (r1 - arg1)**2 + (r2 - arg2)**2)**0.5;\n",
    "\n",
    "dist = np.zeros((len(polar0),len(polar0)))\n",
    "for k in xrange(len(r0)):\n",
    "    dist[k] += distfunct(r0, r1, r2, r0[k], r1[k], r2[k])\n",
    "\n",
    "data = np.zeros((len(polar0),len(polar0),2)) \n",
    "\n",
    "#the below loop is expensive...\n",
    "\n",
    "#store the dot product and the distance between the two nodes we are dotting\n",
    "\n",
    "for i in xrange(len(polar0)):\n",
    "    for j in xrange(len(polar0)):\n",
    "        if i != j:\n",
    "            data[i,j] = np.array([dist[i][j] , polar0[i] * polar0[j] + polar1[i] * polar1[j] + polar2[i] * polar2[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.64176131,   4.24031238,  10.35242499,  17.8552479 ,\n",
       "        25.79324831,  33.41351423,  40.24171227,  45.90614272,\n",
       "        50.13263573,  52.81124012,  53.83949052,  53.22074326,\n",
       "        50.94222159,  47.08687345,  41.82900158,  35.43135742,\n",
       "        28.24807567,  20.78531421,  13.32380852,   6.2167789 ])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_total[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.00779603"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(39.69659216+47.74092078+29.29923654+55.29443464)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array max located at 13.003779 nm\n",
      "Loading data and computing dot products and distances took 29.802030 seconds\n"
     ]
    }
   ],
   "source": [
    "#full algorithm:\n",
    "for t in range(3,4):\n",
    "    start_load = timer()\n",
    "    file_load = iter_loadtxt('/media/john/My Passport/Sphere project data/run2--curl/data'+repr(t)+'.csv',delimiter=',',skiprows=1,dtype=float)\n",
    "    \n",
    "    polar0 = np.asarray([row[1] for row in file_load])\n",
    "    polar1 = np.asarray([row[2] for row in file_load])\n",
    "    polar2 = np.asarray([row[3] for row in file_load])\n",
    "     \n",
    "    polar0ave = np.mean(polar0)\n",
    "    polar1ave = np.mean(polar1)\n",
    "    polar2ave = np.mean(polar2)\n",
    "    \n",
    "    Polar0fluct = np.asarray(polar0 - polar0ave)\n",
    "    Polar1fluct = np.asarray(polar1 - polar1ave)\n",
    "    Polar2fluct = np.asarray(polar2 - polar2ave)\n",
    "    \n",
    "    r0 = np.asarray([row[4] for row in file_load])\n",
    "    r1 = np.asarray([row[5] for row in file_load])\n",
    "    r2 = np.asarray([row[6] for row in file_load])\n",
    "\n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64)\"], target = 'gpu') \n",
    "    def distance_funct(r0, r1, r2, arg0, arg1, arg2):\n",
    "        return ((r0 - arg0)**2 + (r1 - arg1)**2 + (r2 - arg2)**2)**0.5;\n",
    "    \n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64, float64, float64, float64)\"], target='gpu') \n",
    "    def dotproduct_funct(p0, p1, p2, arg0, arg1, arg2, arg0mean, arg1mean, arg2mean):\n",
    "        return (p0 - arg0mean) * (arg0 - arg0mean) + (p1 - arg1mean) * (arg1 - arg0mean) + (p2 - arg2mean) * (arg2 - arg0mean);\n",
    "\n",
    "    dist = np.zeros((len(polar0),len(polar0)))\n",
    "    dots = np.zeros((len(polar0),len(polar0)))\n",
    "    \n",
    "    polar0mean = np.mean(polar0)\n",
    "    polar1mean = np.mean(polar1)\n",
    "    polar2mean = np.mean(polar2)\n",
    "    \n",
    "    for k in xrange(len(polar0)):\n",
    "        dist[k] = distance_funct(r0, r1, r2, r0[k], r1[k], r2[k])\n",
    "        dots[k] = dotproduct_funct(polar0, polar1, polar2, polar0[k], polar1[k], polar2[k], polar0mean, polar1mean, polar2mean)\n",
    "\n",
    "    bin_number = 20\n",
    "    \n",
    "    a = np.amax(dist)\n",
    "    print(\"Array max located at %f nm\" % a)\n",
    "    \n",
    "    r_bins =  np.linspace(0,a+1,bin_number)\n",
    "    load_time = timer() - start_load\n",
    "    \n",
    "    #times to load the above data across our differently sized systems(scales with filesize probably): \n",
    "    \n",
    "    #18.17, 23.013, 29.118, 37.66, 46.793950, 63.81686, 87.457398, 87.112473, 107.036612 ,160.460258, 168.049912, 335.679145 seconds\n",
    "\n",
    "    print(\"Loading data and computing dot products and distances took %f seconds\" % load_time)\n",
    "    \n",
    "    #start_hist_calc = timer()\n",
    "\n",
    "    #cr = np.zeros((len(polar0),bin_number))\n",
    "    #v\n",
    "    #-----This loop right here is the most expensive one----#\n",
    "    #sum_vec = np.zeros((len(polar0),bin_number))\n",
    "    \n",
    "    #for i in range(0,len(polar0)):\n",
    "\n",
    "        #[Nbin, rtest] = np.histogram(dist[i], bins = bin_number, range=None, normed=False, weights=None, density=None)\n",
    "    \n",
    "    #    for n in range(0,bin_number):\n",
    "    #        for j in range(0,len(polar0)):\n",
    "    #            if r_bins[n] < dist[i][j] and dist[i][j] < r_bins[n+1]:\n",
    "    #            #print dist_vec[j], dot_vec[j]\n",
    "    #               sum_vec[i,n] += dots[i][j]\n",
    "\n",
    "    #    cr[i,:] = sum_vec[i,:]\n",
    "    #--------------------------------#    \n",
    "    #hist_calc_time = timer() - start_hist_calc\n",
    "    #print(\"Binning the histograms, sorting data, and calculating the correlation function took %f seconds\" %  hist_calc_time)\n",
    "    \n",
    "    #start_corr_mean = timer()\n",
    "    #for n in range(0,len(r_bins)):\n",
    "    #    Cr[n] = np.mean(cr[0:len(polar0),n])\n",
    "    #time_to_mean = timer() - start_corr_mean \n",
    "    #print(\"Computing the mean took %f seconds\" %  time_to_mean)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33442645,  1.97814286,  4.41877282,  6.59776073,  7.74253634,\n",
       "        7.59261856,  6.14178359,  3.72717723,  0.83220008, -2.04925948,\n",
       "       -4.5395033 , -6.3145933 , -7.15268705, -6.99326662, -5.90265594,\n",
       "       -4.06412025, -1.99554793, -0.38635252,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cr[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.linspace(1,100,10)\n",
    "\n",
    "for n in xrange(10):\n",
    "    q = distance_funct(a,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,   21.,   32.,   43.,   54.,   65.,   76.,   87.,   98.,  109.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing correlations of the size 14.000000 sphere:\n",
      "Loading data and computing dot products and distances took 68.306695 seconds\n",
      "Array max located at 18.993443 nm\n",
      "Compute time: 24.294551\n",
      "Performing correlations of the size 15.000000 sphere:\n",
      "Loading data and computing dot products and distances took 74.295684 seconds\n",
      "Array max located at 19.995366 nm\n",
      "Compute time: 32.118267\n",
      "Performing correlations of the size 16.000000 sphere:\n",
      "Loading data and computing dot products and distances took 83.437861 seconds\n",
      "Array max located at 20.999647 nm\n",
      "Compute time: 41.138889\n",
      "Performing correlations of the size 17.000000 sphere:\n",
      "Loading data and computing dot products and distances took 96.524824 seconds\n",
      "Array max located at 21.992092 nm\n",
      "Compute time: 57.678381\n",
      "Performing correlations of the size 18.000000 sphere:\n",
      "Loading data and computing dot products and distances took 121.305189 seconds\n",
      "Array max located at 23.001598 nm\n",
      "Compute time: 78.981254\n",
      "Performing correlations of the size 19.000000 sphere:\n",
      "Loading data and computing dot products and distances took 142.516126 seconds\n",
      "Array max located at 23.991571 nm\n",
      "Compute time: 104.978715\n",
      "Performing correlations of the size 20.000000 sphere:\n",
      "Loading data and computing dot products and distances took 174.339292 seconds\n",
      "Array max located at 25.000987 nm\n",
      "Compute time: 149.265529\n",
      "Performing correlations of the size 21.000000 sphere:\n",
      "Loading data and computing dot products and distances took 198.131783 seconds\n",
      "Array max located at 26.012057 nm\n",
      "Compute time: 453.818261\n",
      "Performing correlations of the size 22.000000 sphere:\n",
      "Loading data and computing dot products and distances took 236.358738 seconds"
     ]
    }
   ],
   "source": [
    "for t in range(22,30):\n",
    "    print(\"Performing correlations of the size %f sphere:\" % t) \n",
    "    \n",
    "    start_load = timer()\n",
    "    file_load = iter_loadtxt('/media/john/My Passport/sphere-project-new/csv/data'+repr(t-1)+'.csv',delimiter=',',skiprows=1,dtype=float)\n",
    "    \n",
    "    polar0 = np.asarray([row[10] for row in file_load])\n",
    "    polar1 = np.asarray([row[11] for row in file_load])\n",
    "    polar2 = np.asarray([row[12] for row in file_load])\n",
    "     \n",
    "    polar0ave = np.mean(polar0)\n",
    "    polar1ave = np.mean(polar1)\n",
    "    polar2ave = np.mean(polar2)\n",
    "    \n",
    "    Polar0fluct = np.asarray(polar0 - polar0ave)\n",
    "    Polar1fluct = np.asarray(polar1 - polar1ave)\n",
    "    Polar2fluct = np.asarray(polar2 - polar2ave)\n",
    "    \n",
    "    r0 = np.asarray([row[22] for row in file_load])\n",
    "    r1 = np.asarray([row[23] for row in file_load])\n",
    "    r2 = np.asarray([row[24] for row in file_load])\n",
    "\n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64)\"], target = 'gpu') \n",
    "    def distance_funct(r0, r1, r2, arg0, arg1, arg2):\n",
    "        return ((r0 - arg0)**2 + (r1 - arg1)**2 + (r2 - arg2)**2)**0.5;\n",
    "    \n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64, float64, float64, float64)\"], target='gpu') \n",
    "    def dotproduct_funct(p0, p1, p2, arg0, arg1, arg2, arg0mean, arg1mean, arg2mean):\n",
    "        return (p0 - arg0mean) * (arg0 - arg0mean) + (p1 - arg1mean) * (arg1 - arg0mean) + (p2 - arg2mean) * (arg2 - arg0mean);\n",
    "\n",
    "    dist = np.zeros((len(polar0),len(polar0)))\n",
    "    dots = np.zeros((len(polar0),len(polar0)))\n",
    "    \n",
    "    polar0mean = np.mean(polar0)\n",
    "    polar1mean = np.mean(polar1)\n",
    "    polar2mean = np.mean(polar2)\n",
    "    \n",
    "    for k in range(0,len(polar0)):\n",
    "        dist[k] = distance_funct(r0, r1, r2, r0[k], r1[k], r2[k])\n",
    "        dots[k] = dotproduct_funct(polar0, polar1, polar2, polar0[k], polar1[k], polar2[k], polar0mean, polar1mean, polar2mean)\n",
    "\n",
    "    load_time = timer() - start_load\n",
    "    print(\"Loading data and computing dot products and distances took %f seconds\" % load_time) \n",
    "    \n",
    "    bin_number = 25 + t\n",
    "\n",
    "    a = np.amax(dist)\n",
    "    \n",
    "    print(\"Array max located at %f nm\" % a)\n",
    "    r_bins =  np.linspace(0, a + 3*(a - 0)/bin_number, bin_number)\n",
    "\n",
    "    @autojit #the only difference between the serial version of the function and the GPUized version is @autojit!\n",
    "    def sum2d(argdots, argdist, argrbin):\n",
    "\n",
    "        M, N = argdots.shape\n",
    "        Cr = np.zeros(bin_number)\n",
    "        sum_vec = np.zeros((N,len(argrbin)))\n",
    "        result = np.zeros((M,len(argrbin)))\n",
    "        for i in xrange(M):\n",
    "            for n in xrange(len(argrbin)):\n",
    "                for j in xrange(N):\n",
    "                    if argrbin[n] <= argdist[i,j] and argdist[i,j] <= argrbin[n+1]:\n",
    "                        sum_vec[i,n] += argdots[i,j]\n",
    "            result[i,:] = sum_vec[i,:]\n",
    "        \n",
    "        for n in range(0,len(argrbin)):\n",
    "            Cr[n] = np.mean(result[0:M,n])\n",
    "\n",
    "        return Cr\n",
    "\n",
    "\n",
    "    start = timer() #for bin_number = 20\n",
    "    CrAve = sum2d(dots,dist,r_bins)\n",
    "    sumtime = timer() - start\n",
    "    \n",
    "    np.savetxt(\"/media/john/My Passport/sphere-project-new/csv/Cr_gpu_\"+repr(t - 1)+\".csv\", CrAve, delimiter=\",\")\n",
    "    np.savetxt(\"/media/john/My Passport/sphere-project-new/csv/rbins_gpu_\"+repr(t - 1)+\".csv\", r_bins, delimiter=\",\")\n",
    "    \n",
    "    print(\"Compute time: %f\" % sumtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing correlations of the size 15.000000 sphere:\n",
      "Loading data and computing dot products and distances took 343.774257 seconds\n",
      "Array max located at 24.992829 nm\n",
      "Compute time: 879.089498\n",
      "Performing correlations of the size 16.000000 sphere:\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ca02289356d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0marg0mean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marg0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0marg0mean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0marg1mean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0marg0mean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0marg2mean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marg2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0marg0mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolar0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolar0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mdots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolar0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolar0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(15,26):\n",
    "    print(\"Performing correlations of the size %f sphere:\" % t) \n",
    "    \n",
    "    start_load = timer()\n",
    "    file_load = iter_loadtxt('/media/john/My Passport/Sphere project data/run2--curl/data'+repr(t)+'.csv',delimiter=',',skiprows=1,dtype=float)\n",
    "    \n",
    "    polar0 = np.asarray([row[1] for row in file_load])\n",
    "    polar1 = np.asarray([row[2] for row in file_load])\n",
    "    polar2 = np.asarray([row[3] for row in file_load])\n",
    "     \n",
    "    polar0ave = np.mean(polar0)\n",
    "    polar1ave = np.mean(polar1)\n",
    "    polar2ave = np.mean(polar2)\n",
    "    \n",
    "    Polar0fluct = np.asarray(polar0 - polar0ave)\n",
    "    Polar1fluct = np.asarray(polar1 - polar1ave)\n",
    "    Polar2fluct = np.asarray(polar2 - polar2ave)\n",
    "    \n",
    "    r0 = np.asarray([row[4] for row in file_load])\n",
    "    r1 = np.asarray([row[5] for row in file_load])\n",
    "    r2 = np.asarray([row[6] for row in file_load])\n",
    "\n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64)\"], target = 'gpu') \n",
    "    def distance_funct(r0, r1, r2, arg0, arg1, arg2):\n",
    "        return ((r0 - arg0)**2 + (r1 - arg1)**2 + (r2 - arg2)**2)**0.5;\n",
    "    \n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64, float64, float64, float64)\"], target='gpu') \n",
    "    def dotproduct_funct(p0, p1, p2, arg0, arg1, arg2, arg0mean, arg1mean, arg2mean):\n",
    "        return (p0 - arg0mean) * (arg0 - arg0mean) + (p1 - arg1mean) * (arg1 - arg0mean) + (p2 - arg2mean) * (arg2 - arg0mean);\n",
    "\n",
    "    dist = np.zeros((len(polar0),len(polar0)))\n",
    "    dots = np.zeros((len(polar0),len(polar0)))\n",
    "    \n",
    "    polar0mean = np.mean(polar0)\n",
    "    polar1mean = np.mean(polar1)\n",
    "    polar2mean = np.mean(polar2)\n",
    "    \n",
    "    for k in xrange(len(polar0)):\n",
    "        dist[k] = distance_funct(r0, r1, r2, r0[k], r1[k], r2[k])\n",
    "        dots[k] = dotproduct_funct(polar0, polar1, polar2, polar0[k], polar1[k], polar2[k], polar0mean, polar1mean, polar2mean)\n",
    "\n",
    "    load_time = timer() - start_load\n",
    "    print(\"Loading data and computing dot products and distances took %f seconds\" % load_time) \n",
    "    \n",
    "    bin_number = 25\n",
    "\n",
    "    a = np.amax(dist)\n",
    "    \n",
    "    print(\"Array max located at %f nm\" % a)\n",
    "    r_bins =  np.linspace(0, a + 3*(a - 0)/bin_number, bin_number)\n",
    "\n",
    "    @autojit #the only difference between the serial version of the function and the GPUized version is @autojit!\n",
    "    def sum2d(argdots, argdist, argrbin):\n",
    "\n",
    "        M, N = argdots.shape\n",
    "        Cr = np.zeros(bin_number)\n",
    "        sum_vec = np.zeros((N,len(argrbin)))\n",
    "        result = np.zeros((M,len(argrbin)))\n",
    "        for i in xrange(M):\n",
    "            for n in xrange(len(argrbin)):\n",
    "                for j in xrange(N):\n",
    "                    if argrbin[n] <= argdist[i,j] and argdist[i,j] <= argrbin[n+1]:\n",
    "                        sum_vec[i,n] += argdots[i,j]\n",
    "            result[i,:] = sum_vec[i,:]\n",
    "        \n",
    "        for n in range(0,len(argrbin)):\n",
    "            Cr[n] = np.mean(result[0:M,n])\n",
    "\n",
    "        return Cr\n",
    "\n",
    "\n",
    "    start = timer() #for bin_number = 20\n",
    "    CrAve = sum2d(dots,dist,r_bins)\n",
    "    sumtime = timer() - start\n",
    "    \n",
    "    np.savetxt(\"/media/john/My Passport/Sphere project data/run2--curl/Cr_gpu_\"+repr(t)+\".csv\", CrAve, delimiter=\",\")\n",
    "    np.savetxt(\"/media/john/My Passport/Sphere project data/run2--curl/rbins_gpu_\"+repr(t)+\".csv\", r_bins, delimiter=\",\")\n",
    "    \n",
    "    print(\"Compute time: %f\" % sumtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing correlations of the size 19.000000 sphere:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (95405) into shape (6814)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7dda615ded89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolar0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistance_funct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mdots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdotproduct_funct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolar0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar0mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar1mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar2mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (95405) into shape (6814)"
     ]
    }
   ],
   "source": [
    "for t in range(19,20):\n",
    "    print(\"Performing correlations of the size %f sphere:\" % t) \n",
    "    \n",
    "    dint =  14\n",
    "    \n",
    "    start_load = timer()\n",
    "    file_load = iter_loadtxt('/media/john/My Passport/Sphere project data/run2--curl/data'+repr(t)+'.csv',delimiter=',',skiprows=1,dtype=float)\n",
    "    \n",
    "    polar0 = np.asarray([row[1] for row in file_load])\n",
    "    polar1 = np.asarray([row[2] for row in file_load])\n",
    "    polar2 = np.asarray([row[3] for row in file_load])\n",
    "    \n",
    "    r0 = np.asarray([row[4] for row in file_load])\n",
    "    r1 = np.asarray([row[5] for row in file_load])\n",
    "    r2 = np.asarray([row[6] for row in file_load])\n",
    "\n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64)\"], target = 'gpu') \n",
    "    def distance_funct(r0, r1, r2, arg0, arg1, arg2):\n",
    "        return ((r0 - arg0)**2 + (r1 - arg1)**2 + (r2 - arg2)**2)**0.5;\n",
    "    \n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64, float64, float64, float64)\"], target='gpu') \n",
    "    def dotproduct_funct(p0, p1, p2, arg0, arg1, arg2, arg0mean, arg1mean, arg2mean):\n",
    "        return (p0 - arg0mean) * (arg0 - arg0mean) + (p1 - arg1mean) * (arg1 - arg0mean) + (p2 - arg2mean) * (arg2 - arg0mean);\n",
    "\n",
    "    dist = np.zeros((len(polar0)/14,len(polar0)/14))\n",
    "    dots = np.zeros((len(polar0)/14,len(polar0)/14))\n",
    "    \n",
    "    polar0mean = np.mean(polar0)\n",
    "    polar1mean = np.mean(polar1)\n",
    "    polar2mean = np.mean(polar2)\n",
    "    \n",
    "    for k in range(0,len(polar0),14):\n",
    "        dist[k] = distance_funct(r0, r1, r2, r0[k], r1[k], r2[k])\n",
    "        dots[k] = dotproduct_funct(polar0, polar1, polar2, polar0[k], polar1[k], polar2[k], polar0mean, polar1mean, polar2mean)\n",
    "\n",
    "    load_time = timer() - start_load\n",
    "    print(\"Loading data and computing dot products and distances took %f seconds\" % load_time) \n",
    "    \n",
    "    bin_number = 25\n",
    "\n",
    "    a = np.amax(dist)\n",
    "    \n",
    "    print(\"Array max located at %f nm\" % a)\n",
    "    r_bins =  np.linspace(0, a + 3*(a - 0)/bin_number, bin_number)\n",
    "\n",
    "    @autojit #the only difference between the serial version of the function and the GPUized version is @autojit!\n",
    "    def sum2d(argdots, argdist, argrbin):\n",
    "\n",
    "        M, N = argdots.shape\n",
    "        Cr = np.zeros(bin_number)\n",
    "        sum_vec = np.zeros((N,len(argrbin)))\n",
    "        result = np.zeros((M,len(argrbin)))\n",
    "        for i in range(0,M,14):\n",
    "            for n in xrange(len(argrbin)):\n",
    "                for j in xrange(0,N,14):\n",
    "                    if argrbin[n] <= argdist[i,j] and argdist[i,j] <= argrbin[n+1]:\n",
    "                        sum_vec[i,n] += argdots[i,j]\n",
    "            result[i,:] = sum_vec[i,:]\n",
    "        \n",
    "        for n in range(0,len(argrbin)):\n",
    "            Cr[n] = np.mean(result[0:len(result),n])\n",
    "\n",
    "        return Cr\n",
    "\n",
    "    # we make larger sphere correlations coarser (16 needs _int_ == 3, 17 needs _int_ == 6)\n",
    "    start = timer() #for bin_number = 20\n",
    "    CrAve = sum2d(dots,dist,r_bins)\n",
    "    sumtime = timer() - start\n",
    "    \n",
    "    np.savetxt(\"/media/john/My Passport/Sphere project data/run2--curl/Cr_gpu_\"+repr(t)+\".csv\", CrAve, delimiter=\",\")\n",
    "    np.savetxt(\"/media/john/My Passport/Sphere project data/run2--curl/rbins_gpu_\"+repr(t)+\".csv\", r_bins, delimiter=\",\")\n",
    "    \n",
    "    print(\"Compute time: %f\" % sumtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4.198216\n"
     ]
    }
   ],
   "source": [
    "start = timer() #for bin_number = 30\n",
    "n2 = sum2d(dots,dist,r_bins)\n",
    "sumtime = timer() - start\n",
    "print(\"Time: %f\" % sumtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04021924,  0.53595062,  1.2793013 ,  2.15336015,  3.06819442,\n",
       "        3.87449114,  4.47031047,  4.78965736,  4.77619817,  4.46308878,\n",
       "        3.86202413,  3.04801654,  2.056992  ,  0.9762016 , -0.13397134,\n",
       "       -1.20776503, -2.17883605, -3.02525056, -3.69282413, -4.15640061,\n",
       "       -4.39101193, -4.3919297 , -4.1756501 , -3.75079536, -3.1320893 ,\n",
       "       -2.38620248, -1.60660877, -0.88018183, -0.28448872,  0.        ])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4.288260\n"
     ]
    }
   ],
   "source": [
    "start = timer() #for bin_number = 35\n",
    "n3 = sum2d(dots,dist,r_bins)\n",
    "sumtime = timer() - start\n",
    "print(\"Time: %f\" % sumtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(r_bins, n3);\n",
    "plt.ylabel('Cr', fontsize = 27); plt.xlabel('r [nm]', fontsize = 27);\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argrbin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-196e7303163b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0margrbin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0margdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0margdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0margrbin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                 \u001b[0msum_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margdots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'argrbin' is not defined"
     ]
    }
   ],
   "source": [
    "sum_vec = np.zeros((100,20))\n",
    "result = np.zeros((100,20))\n",
    "for i in xrange(100):\n",
    "    for n in xrange(20):\n",
    "        for j in xrange(100):\n",
    "            if argrbin[n] <= argdist[i,j] and argdist[i,j] <= argrbin[n]:\n",
    "                sum_vec[i,n] += argdots[i,j]\n",
    "    result[i,:] = sum_vec[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.55965765,   1.1193153 ,   1.67897296,\n",
       "         2.23863061,   2.79828826,   3.35794591,   3.91760356,\n",
       "         4.47726122,   5.03691887,   5.59657652,   6.15623417,\n",
       "         6.71589182,   7.27554948,   7.83520713,   8.39486478,\n",
       "         8.95452243,   9.51418008,  10.07383774,  10.63349539,\n",
       "        11.19315304,  11.75281069,  12.31246834,  12.872126  ,  13.43178365])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, a + 3*(a - 0)/bin_number, bin_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,10,2):\n",
    "    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing correlations of the size 0.000000 sphere:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f66cc0a7ff6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistance_funct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#should clear r from memory here is it del r0?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mdots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdotproduct_funct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolar0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar0mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar1mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolar2mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;31m#should clear p from memory here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mload_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/john/anaconda2/lib/python2.7/site-packages/numba/cuda/dispatcher.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m     93\u001b[0m                       \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \"\"\"\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mCUDAUFuncMechanism\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/john/anaconda2/lib/python2.7/site-packages/numba/npyufunc/deviceufunc.pyc\u001b[0m in \u001b[0;36mcall\u001b[1;34m(cls, typemap, args, kws)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;31m# Begin call resolution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mcr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypemap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[0mresty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/john/anaconda2/lib/python2.7/site-packages/numba/npyufunc/deviceufunc.pyc\u001b[0m in \u001b[0;36mget_arguments\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resolve_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0marys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_actual_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/john/anaconda2/lib/python2.7/site-packages/numba/npyufunc/deviceufunc.pyc\u001b[0m in \u001b[0;36m_broadcast\u001b[1;34m(self, arys)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_device_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m                     \u001b[0marys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/john/anaconda2/lib/python2.7/site-packages/numba/cuda/dispatcher.pyc\u001b[0m in \u001b[0;36mis_device_array\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_device_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdevicearray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_cuda_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhostary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#this is for the slab... seems to work..\n",
    "\n",
    "for t in range(0,1):\n",
    "    print(\"Performing correlations of the size %f sphere:\" % t) \n",
    "\n",
    "    dint = 3;\n",
    "    \n",
    "    start_load = timer()\n",
    "    file_load = iter_loadtxt('/media/john/My Passport/slabs/serge_tests/data0.csv',delimiter=',',skiprows=1,dtype=float)\n",
    "    \n",
    "    polar0 = np.asarray([row[0] for row in file_load[0:len(file_load[:,0]):dint]])\n",
    "    polar1 = np.asarray([row[1] for row in file_load[0:len(file_load[:,1]):dint]])\n",
    "    polar2 = np.asarray([row[2] for row in file_load[0:len(file_load[:,2]):dint]])\n",
    "    \n",
    "    r0 = np.asarray([row[5] for row in file_load[0:len(file_load[:,5]):dint]])\n",
    "    r1 = np.asarray([row[6] for row in file_load[0:len(file_load[:,6]):dint]])\n",
    "    r2 = np.asarray([row[7] for row in file_load[0:len(file_load[:,7]):dint]])\n",
    "\n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64)\"], target = 'gpu') \n",
    "    def distance_funct(r0, r1, r2, arg0, arg1, arg2):\n",
    "        return ((r0 - arg0)**2 + (r1 - arg1)**2 + (r2 - arg2)**2)**0.5;\n",
    "    \n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64, float64, float64, float64)\"], target='gpu') \n",
    "    def dotproduct_funct(p0, p1, p2, arg0, arg1, arg2, arg0mean, arg1mean, arg2mean):\n",
    "        return (p0 - arg0mean) * (arg0 - arg0mean) + (p1 - arg1mean) * (arg1 - arg0mean) + (p2 - arg2mean) * (arg2 - arg0mean);\n",
    "\n",
    "    dist = np.zeros((len(polar0),len(polar0)))\n",
    "    dots = np.zeros((len(polar0),len(polar0)))\n",
    "    \n",
    "    polar0mean = np.mean(polar0)\n",
    "    polar1mean = np.mean(polar1)\n",
    "    polar2mean = np.mean(polar2)\n",
    "    \n",
    "    for k in range(0,len(polar0)):\n",
    "        dist[k] = distance_funct(r0, r1, r2, r0[k], r1[k], r2[k])\n",
    "        #should clear r from memory here is it del r0?\n",
    "        dots[k] = (1/(0.8*0.8))*dotproduct_funct(polar0, polar1, polar2, polar0[k], polar1[k], polar2[k], polar0mean, polar1mean, polar2mean)\n",
    "        #should clear p from memory here\n",
    "    load_time = timer() - start_load\n",
    "    print(\"Loading data and computing dot products and distances took %f seconds\" % load_time) \n",
    "    \n",
    "    bin_number = 25\n",
    "    \n",
    "    a = np.amax(dist)\n",
    "    \n",
    "    print(\"Array max located at %f nm\" % a)\n",
    "    r_bins =  np.linspace(0, a + 3*(a - 0)/bin_number, bin_number)\n",
    "\n",
    "    @autojit #the only difference between the serial version of the function and the GPUized version is @autojit!\n",
    "    def sum2d(argdots, argdist, argrbin):\n",
    "\n",
    "        M, N = argdots.shape\n",
    "        Cr = np.zeros(bin_number)\n",
    "        sum_vec = np.zeros((N,len(argrbin)))\n",
    "        result = np.zeros((M,len(argrbin)))\n",
    "        for i in range(0,M):\n",
    "            for n in xrange(len(argrbin)):\n",
    "                for j in xrange(0,N):\n",
    "                    if argrbin[n] <= argdist[i,j] and argdist[i,j] <= argrbin[n+1]:\n",
    "                        sum_vec[i,n] += argdots[i,j]\n",
    "            result[i,:] = sum_vec[i,:]\n",
    "        \n",
    "        for n in range(0,len(argrbin)):\n",
    "            Cr[n] = np.mean(result[0:len(result),n])\n",
    "\n",
    "        return Cr\n",
    "\n",
    "    # we make larger sphere correlations coarser (16 needs _int_ == 3, 17 needs _int_ == 6)\n",
    "    start = timer() #for bin_number = 20\n",
    "    CrAve = sum2d(dots,dist,r_bins)\n",
    "    del polar0, polar1, polar2, r0, r1, r2, polar0mean, polar1mean, polar2mean, dots, dist\n",
    "    sumtime = timer() - start\n",
    "    \n",
    "    np.savetxt(\"/media/john/My Passport/slabs/serge_tests/Cr_gpu_\"+repr(dint)+\"_\"+repr(t)+\"_\"+repr(bin_number)+\".csv\", CrAve, delimiter=\",\")\n",
    "    np.savetxt(\"/media/john/My Passport/slabs/serge_tests/rbins_gpu_\"+repr(dint)+\"_\"+repr(t)+\"_\"+repr(bin_number)+\".csv\", r_bins, delimiter=\",\")\n",
    "    \n",
    "    del bin_number\n",
    "    \n",
    "    print(\"Compute time: %f\" % sumtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing correlations of the size 42.000000 sphere:\n",
      "Loading data and computing dot products and distances took 182.350452 seconds\n",
      "Array max located at 46.960030 nm\n",
      "Compute time: 205.973151\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "for t in range(42,43):\n",
    "    print(\"Performing correlations of the size %f sphere:\" % t) \n",
    "    #RAM-wise we can do dint = 1 up till 20, but then dint = 2 up till 28, 3 up till 32, 4  at 33, 5 at 37, 6 at 40, 7 @41\n",
    "    dint = 7\n",
    "    #if t <= 14:\n",
    "    #    dint = 1\n",
    "    #if t == 15:\n",
    "    #    dint = 2\n",
    "    #if t == 16:\n",
    "    #    dint = 3\n",
    "    #t == 17:\n",
    "    #    dint = 4\n",
    "    \n",
    "    start_load = timer()\n",
    "    file_load = iter_loadtxt('/media/john/My Passport/sphere-project-new/csv/data'+repr(t-1)+'.csv',delimiter=',',skiprows=1,dtype=float)\n",
    "    \n",
    "    polar0 = np.asarray([row[10] for row in file_load[0:len(file_load[:,10]):dint]])\n",
    "    polar1 = np.asarray([row[11] for row in file_load[0:len(file_load[:,11]):dint]])\n",
    "    polar2 = np.asarray([row[12] for row in file_load[0:len(file_load[:,12]):dint]])\n",
    "    \n",
    "    polarmag = (polar0*polar0 + polar1*polar1 + polar2*polar2)**(0.5)\n",
    "    \n",
    "    polar0d = polar0 / polarmag\n",
    "    polar1d = polar1 / polarmag\n",
    "    polar2d = polar2 / polarmag\n",
    "    \n",
    "    r0 = np.asarray([row[22] for row in file_load[0:len(file_load[:,22]):dint]])\n",
    "    r1 = np.asarray([row[23] for row in file_load[0:len(file_load[:,23]):dint]])\n",
    "    r2 = np.asarray([row[24] for row in file_load[0:len(file_load[:,24]):dint]])\n",
    "\n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64)\"], target = 'gpu') \n",
    "    def distance_funct(r0, r1, r2, arg0, arg1, arg2):\n",
    "        return ((r0 - arg0)**2 + (r1 - arg1)**2 + (r2 - arg2)**2)**0.5;\n",
    "    \n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64, float64, float64, float64)\"], target='gpu') \n",
    "    def dotproduct_funct(p0, p1, p2, arg0, arg1, arg2, arg0mean, arg1mean, arg2mean):\n",
    "        return (p0 - arg0mean) * (arg0 - arg0mean) + (p1 - arg1mean) * (arg1 - arg0mean) + (p2 - arg2mean) * (arg2 - arg0mean);\n",
    "\n",
    "    dist = np.zeros((len(polar0),len(polar0)))\n",
    "    dots = np.zeros((len(polar0),len(polar0)))\n",
    "    \n",
    "    #polarmean = np.zeros(25)\n",
    "    \n",
    "    #polar0mean = np.mean(polar0)\n",
    "    #polar1mean = np.mean(polar1)\n",
    "    #polar2mean = np.mean(polar2)\n",
    "    \n",
    "    polar0mean = 0\n",
    "    polar1mean = 0\n",
    "    polar2mean = 0\n",
    "    \n",
    "    for k in range(0,len(polar0)):\n",
    "        dist[k] = distance_funct(r0, r1, r2, r0[k], r1[k], r2[k])\n",
    "        #should clear r from memory here is it del r0?\n",
    "        dots[k] = dotproduct_funct(polar0d, polar1d, polar2d, polar0d[k], polar1d[k], polar2d[k], polar0mean, polar1mean, polar2mean)\n",
    "        #should clear p from memory here\n",
    "    load_time = timer() - start_load\n",
    "    print(\"Loading data and computing dot products and distances took %f seconds\" % load_time) \n",
    "    \n",
    "    bin_number = 25 + t\n",
    "    \n",
    "    a = np.amax(dist)\n",
    "    \n",
    "    print(\"Array max located at %f nm\" % a)\n",
    "    r_bins =  np.linspace(0, a + 3*(a - 0)/bin_number, bin_number)\n",
    "\n",
    "    @autojit #the only difference between the serial version of the function and the GPUized version is @autojit!\n",
    "    def sum2d(argdots, argdist, argrbin):\n",
    "\n",
    "        M, N = argdots.shape\n",
    "        Cr = np.zeros(bin_number)\n",
    "        sum_vec = np.zeros((N,len(argrbin)))\n",
    "        result = np.zeros((M,len(argrbin)))\n",
    "        for i in range(0,M):\n",
    "            for n in xrange(len(argrbin)):\n",
    "                for j in xrange(0,N):\n",
    "                    if argrbin[n] <= argdist[i,j] and argdist[i,j] <= argrbin[n+1]:\n",
    "                        sum_vec[i,n] += argdots[i,j]\n",
    "            result[i,:] = sum_vec[i,:]\n",
    "        \n",
    "        for n in range(0,len(argrbin)):\n",
    "            Cr[n] = np.mean(result[0:len(result),n])\n",
    "\n",
    "        return Cr\n",
    "    \n",
    "    #polarmean[t] = (polar0mean * polar0mean + polar1mean * polar1mean + polar2mean * polar2mean)**(0.5)\n",
    "    \n",
    "    # we make larger sphere correlations coarser (16 needs _int_ == 3, 17 needs _int_ == 6)\n",
    "    start = timer() #for bin_number = 20\n",
    "    CrAve = sum2d(dots,dist,r_bins)\n",
    "    #del polar0, polar1, polar2, r0, r1, r2, polar0mean, polar1mean, polar2mean, dots, dist\n",
    "    sumtime = timer() - start\n",
    "    \n",
    "    np.savetxt(\"/media/john/My Passport/sphere-project-new/csv/director_Cr_gpu_\"+repr(t - 1)+\".csv\", CrAve, delimiter=\",\")\n",
    "    np.savetxt(\"/media/john/My Passport/sphere-project-new/csv/director_rbins_gpu_\"+repr(t - 1)+\".csv\", r_bins, delimiter=\",\")\n",
    "    \n",
    "    del bin_number, dint\n",
    "    \n",
    "    print(\"Compute time: %f\" % sumtime)\n",
    "print(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3245981557686804"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(polarmag**(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'polar1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1f2678fb7e8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mpolar1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'polar1' is not defined"
     ]
    }
   ],
   "source": [
    "del polar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del polar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-933950a0ef9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mr0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'r0' is not defined"
     ]
    }
   ],
   "source": [
    "del r0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f89831ae5d13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'r1' is not defined"
     ]
    }
   ],
   "source": [
    "del r1, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_load = iter_loadtxt('/media/john/My Passport/slabs/serge_tests/data0.csv',delimiter=',',skiprows=1,dtype=float)\n",
    "    \n",
    "polar0 = np.asarray([row[0] for row in file_load[0:len(file_load[:,0]):dint]])\n",
    "polar1 = np.asarray([row[1] for row in file_load[0:len(file_load[:,1]):dint]])\n",
    "polar2 = np.asarray([row[2] for row in file_load[0:len(file_load[:,2]):dint]])\n",
    "    \n",
    "r0 = np.asarray([row[5] for row in file_load[0:len(file_load[:,3]):dint]])\n",
    "r1 = np.asarray([row[5] for row in file_load[0:len(file_load[:,5]):dint]])\n",
    "r2 = np.asarray([row[6] for row in file_load[0:len(file_load[:,6]):dint]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-40.   , -40.027, -38.   , ...,  31.   ,  35.   ,  39.   ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "r0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-40.   , -40.027, -38.   , ...,  31.   ,  35.   ,  39.   ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing correlations of the size 19.000000 sphere:\n",
      "Loading data and computing dot products and distances took 124.297351 seconds\n",
      "Array max located at 40.972596 nm\n",
      "Correlating 31802.000000 points:\n",
      "Compute time: 50.632598\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "for t in range(19,20):\n",
    "    print(\"Performing correlations of the size %f sphere:\" % t) \n",
    "\n",
    "    dint = 3\n",
    "    #if t <= 14:\n",
    "    #    dint = 1\n",
    "    #if t == 15:\n",
    "    #    dint = 2\n",
    "    #if t == 16:\n",
    "    #    dint = 3\n",
    "    #t == 17:\n",
    "    #    dint = 4\n",
    "    \n",
    "    start_load = timer()\n",
    "    file_load = iter_loadtxt('/media/john/My Passport/Sphere project data/run2--curl/data'+repr(t)+'.csv',delimiter=',',skiprows=1,dtype=float)\n",
    "    \n",
    "    polar0 = np.asarray([row[0] for row in file_load[0:len(file_load[:,0]):dint]])\n",
    "    polar1 = np.asarray([row[1] for row in file_load[0:len(file_load[:,1]):dint]])\n",
    "    polar2 = np.asarray([row[2] for row in file_load[0:len(file_load[:,2]):dint]])\n",
    "    \n",
    "    r0 = np.asarray([row[5] for row in file_load[0:len(file_load[:,3]):dint]])\n",
    "    r1 = np.asarray([row[5] for row in file_load[0:len(file_load[:,5]):dint]])\n",
    "    r2 = np.asarray([row[6] for row in file_load[0:len(file_load[:,6]):dint]])\n",
    "\n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64)\"], target = 'gpu') \n",
    "    def distance_funct(r0, r1, r2, arg0, arg1, arg2):\n",
    "        return ((r0 - arg0)**2 + (r1 - arg1)**2 + (r2 - arg2)**2)**0.5;\n",
    "    \n",
    "    @vectorize([\"float64(float64, float64, float64, float64, float64, float64, float64, float64, float64)\"], target='gpu') \n",
    "    def dotproduct_funct(p0, p1, p2, arg0, arg1, arg2, arg0mean, arg1mean, arg2mean):\n",
    "        return (p0 - arg0mean) * (arg0 - arg0mean) + (p1 - arg1mean) * (arg1 - arg0mean) + (p2 - arg2mean) * (arg2 - arg0mean);\n",
    "\n",
    "    dist = np.zeros((len(polar0),len(polar0)))\n",
    "    dots = np.zeros((len(polar0),len(polar0)))\n",
    "    \n",
    "    polar0mean = 0.0\n",
    "    polar1mean = 0.0\n",
    "    polar2mean = 0.0\n",
    "\n",
    "    for k in range(0,len(polar0)):\n",
    "        dist[k] = distance_funct(r0, r1, r2, r0[k], r1[k], r2[k])\n",
    "        #should clear r from memory here is it del r0?\n",
    "        dots[k] = (1/(0.8*0.8))*dotproduct_funct(polar0, polar1, polar2, polar0[k], polar1[k], polar2[k], polar0mean, polar1mean, polar2mean)\n",
    "        #should clear p from memory here\n",
    "    load_time = timer() - start_load\n",
    "\n",
    "    print(\"Loading data and computing dot products and distances took %f seconds\" % load_time) \n",
    "    \n",
    "    bin_number = 25\n",
    "    \n",
    "    a = np.amax(dist)\n",
    "    \n",
    "    print(\"Array max located at %f nm\" % a)\n",
    "    r_bins =  np.linspace(0, a + 3*(a - 0)/bin_number, bin_number)\n",
    "\n",
    "    @autojit #the only difference between the serial version of the function and the GPUized version is @autojit!\n",
    "    def sum2d(argdots, argdist, argrbin):\n",
    "\n",
    "        M, N = argdots.shape\n",
    "        q = len(argrbin)\n",
    "        Cr = np.zeros(bin_number)\n",
    "        sum_vec = np.zeros((N,q))\n",
    "        result = np.zeros((M,q))\n",
    "        for i in range(0,M):\n",
    "            for n in xrange(q):\n",
    "                for j in xrange(0,N):\n",
    "                    if argrbin[n] <= argdist[i,j] and argdist[i,j] <= argrbin[n+1]:\n",
    "                        sum_vec[i,n] += argdots[i,j]\n",
    "            result[i,:] = sum_vec[i,:]\n",
    "        \n",
    "        for n in range(0,q):\n",
    "            Cr[n] = np.mean(result[0:len(result),n])\n",
    "\n",
    "        return Cr\n",
    "    print(\"Correlating %f points:\" % len(polar0))\n",
    "    \n",
    "    # we make larger sphere correlations coarser (16 needs _int_ == 3, 17 needs _int_ == 6)\n",
    "    start = timer() #for bin_number = 20\n",
    "    CrAve = sum2d(dots,dist,r_bins)\n",
    "    del polar0, polar1, polar2, r0, r1, r2, polar0mean, polar1mean, polar2mean, dots, dist\n",
    "    sumtime = timer() - start\n",
    "    \n",
    "    np.savetxt(\"/media/john/My Passport/Sphere project data/run2--curl/noAve_Cr_gpu_\"+repr(dint)+\"_\"+repr(t)+\"_\"+repr(bin_number)+\".csv\", CrAve, delimiter=\",\")\n",
    "    np.savetxt(\"/media/john/My Passport/Sphere project data/run2--curl/noAve_rbins_gpu_\"+repr(dint)+\"_\"+repr(t)+\"_\"+repr(bin_number)+\".csv\", r_bins, delimiter=\",\")\n",
    "    \n",
    "    del bin_number, dint\n",
    "    \n",
    "    print(\"Compute time: %f\" % sumtime)\n",
    "print(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del polar0, polar1, polar2, r0, r1, r2, polar0mean, polar1mean, polar2mean, dots, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
